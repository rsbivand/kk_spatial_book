##############################################
#Przestrzenne metody ilościowe w R: statystyka, ekonometria, uczenie maszynowe, analiza danych
#Redakcja Katarzyna Kopczewska
#Autorzy: Katarzyna Kopczewska, Maria Kubara, Piotr Ćwiakowski, Mateusz Kopyt, Piotr Wójcik, Alessandro Festi, Kateryna Zabarina
#Warszawa, 2020, CeDeWu
#Wydanie książki zostało sfinansowane z grantu Narodowego Centrum Nauki (NCN) pt. Modele ekonometryczne przestrzenne ze stałą i zmienną strukturą sąsiedztwa. Zastosowanie do wyceny nieruchomości i lokalizacji firm (OPUS 12, umowa nr UMO-2016/23/B/HS4/02363).
#Książka została wydana w angielskiej wersji językowej jako: Applied Spatial Statistics and Econometrics: Data Analysis in R (redakcja Katarzyna Kopczewska, autorzy: Katarzyna Kopczewska, Maria Kubara, Piotr Ćwiakowski, Mateusz Kopyt, Piotr Wójcik, Alessandro Festi, Kateryna Zabarina), Routledge, 2020
##############################################

#Rozdział 9
#Przestrzenne próbkowanie i bootstrap 
#Katarzyna Kopczewska, Piotr Ćwiakowski 

#9.1 Przestrzenne dane punktowe – klasy obiektów i agregacja przestrzenna

# zbiór danych punktowych – 5000 obserwacji
firmy<-read.csv("geoloc data.csv", header=TRUE, dec=",", sep=";")
firmy.lim<-firmy[1:5000,]

#przypomienie – wczytywanie obiektów przestrzennych
woj<-readOGR(".", "wojewodztwa") # 16 jedn. 
woj<- spTransform(woj, CRS("+proj=longlat +datum=NAD83"))

pow<-readOGR(".", "powiaty") # 380 jedn. 
pow<- spTransform(pow, CRS("+proj=longlat +datum=NAD83"))

#przypomnienie – tworzenie wycinków mapy
dane<-read.csv("dane_pow_2019.csv", header=TRUE, dec=",", sep=";")
woj.df<-as.data.frame(woj)
lub.woj<-woj[woj.df$jpt_nazwa_=="lubelskie", ]
dane15<-dane[dane$rok==2015, ]
lub.pow<-pow[dane15$wojew_nazwa=="Lubelskie", ]

# wycinki mapy (por. Rozdział 2) oraz dane punktowe
plot(lub.woj, lwd=2) # wycinek mapy wojewódzkiej utworzony wcześniej
plot(lub.pow, add=TRUE) # wycinek mapy powiatowej 
points(firmy.lim[,12:13], pch=".") # lokalizacje xy punktów 

# zmiana klasy danych punktowych z data.frame na SpatialPoints
firmy.lim.sp<-SpatialPoints(firmy.lim[,12:13], proj4string=CRS(proj4string(lub.pow)))

pts<-over(firmy.lim.sp, lub.pow) # przynależność pkt do obszarów
pts.ag<-aggregate(pts$jpt_nazwa_, by=list(pts$jpt_nazwa_), length)

# wykres słupkowy poziomy – liczba punktów w powiatach
par(mar=c(2,10,2,2)) # kolejność marginesów: dół, lewy, góra, prawy
barplot(pts.ag$x, horiz=TRUE, names.arg=pts.ag$Group.1, las=1, xlim=c(0,700))
abline(v=(1:7)*100, lty=3)
par(mar=c(2,2,2,2))

library(spatstat)
library(rgdal)
library(maptools)
lub.pow<-spTransform(lub.pow, CRS("+proj=merc +datum=NAD83")) # planarne
lub.pow.owin<-as(lub.pow, "owin") # konwersja SpatialPolygon do owin

# zmiana projekcji punktów
proj4string(firmy.lim.sp)<-CRS("+proj=longlat +datum=NAD83") # sferyczne
firmy.lim.sp<-spTransform(firmy.lim.sp, CRS("+proj=merc +datum=NAD83")) 

# obiekt klasy ppp - bez wartości i z wartościami (marks)
firmy.lim.ppp<-ppp(firmy.lim.sp@coords[,1], firmy.lim.sp@coords[,2], window=lub.pow.owin)
firmy.lim.ppp.m<-ppp(firmy.lim.sp@coords[,1], firmy.lim.sp@coords[,2], window=lub.pow.owin, marks=firmy.lim[,18])

# wykres punktów (klasa ppp) – lokalizacja i wartość w punkcie
plot(firmy.lim.ppp) # wykres punktów (klasa ppp) – wyłącznie lokalizacja
plot(firmy.lim.ppp.m, cex=0.8, border="red") 

#9.2 Spatial sampling - losowanie / generowanie nowych punktów na powierzchni

# utworzenie wycinka mapy – województwo (NTS2) Lubelskie
woj.df<-as.data.frame(woj) 
lub.woj<-woj[woj.df$jpt_nazwa_=="lubelskie", ] 

# rysunek wylosowanych punktów – rozkład regularny
plot(lub.woj, main="Regular dots in Lubelskie NTS2")
points(spsample(lub.woj, n=1000, "regular"), pch=".", cex=2)

# rysunek wylosowanych punktów – rozkład losowy
plot(lub.woj, main="Random dots in Lubelskie NTS2")
points(spsample(lub.woj, n=1000, "random"), pch=".", cex=2)

# rysunek wylosowanych punktów – losowanie warstwowe
plot(lub.woj, main="Stratified dots in Lubelskie NTS2")
points(spsample(lub.woj, n=1000, "stratified"), pch=".", cex=2)

# rysunek wylosowanych punktów – losowanie niewyrównane
plot(lub.woj, main="Nonaligned dots in Lubelskie NTS2")
points(spsample(lub.woj, n=1000, "nonaligned"), pch=".", cex=2)

# rysunek wylosowanych punktów – rozkład heksagonalny
plot(lub.woj, main="Hexagonal dots in Lubelskie NTS2")
points(spsample(lub.woj, n=1000, "hexagonal"), pch=".", cex=2)

# rysunek wylosowanych punktów – rozkład klastrowany
plot(lub.woj, main="Clustered dots in Lubelskie NTS2")
points(spsample(lub.woj, n=1000, "clustered"), pch=".", cex=2)

# Rys.9.3a - wylosowane punkty – cała mapa wielo-regionalna
plot(woj, main="Losowe punkty w Polsce (w 16 regionach)")
points(spsample(woj, n=2000, "random"), pch=".", cex=2)

# Rys.9.3b - wylosowane punkty – region z mapy wielo-regionalnej
plot(woj, main="Losowe punkty w wybranym regionie (1 z 16)")
points(spsample(woj@polygons[[1]], n=200, "random"), pch=".", cex=2)

lub.woj<-spTransform(lub.woj, CRS("+proj=merc +datum=NAD83")) # planarne
lub.woj.owin<-as(lub.woj, "owin") # konwersja SpatialPolygon do owin
r1<-rstrat(win=lub.woj.owin, nx=10, ny=10, k=5) # Rys.9.4a
plot(r1, main="66 kafli, k=5 obserwacji w kaflu")

r2<-rstrat(win=lub.pow.owin, nx=15, ny=15, k=3) # Rys.9.4b
plot(r2, main="431 kafli, k=3 obserwacji w kaflu")

r3<-rsyst(win=lub.woj.owin, nx=10, ny=10) # rozkład równomierny
plot(r3, main="63 regularne punkty") # kontur wojewódzki

r4<-rsyst(win=lub.pow.owin, nx=15, ny=15) # rozkład równomierny
plot(r4, main="140 regularnych punktów") # kontur powiatowy

#9.3 Spatial sampling - losowanie podpróby z istniejących punktów
#9.3.1 Losowanie proste

#firmy.lim<-firmy[1:5000,] # przypomnienie zbioru danych
wynik<-matrix(0, nrow=50, ncol=30)
for(i in 1:30){
wynik[,i]<-sample(1:5000, size=50, replace=TRUE)}
wynik[1:5, 1:5] # wynik losownia ID

a1<-as.data.frame(table(wynik))
head(a1)

firmy.lim$ID<-1:5000
firmy.m<-merge(firmy.lim, a1, by.x="ID", by.y="wynik", all.x=TRUE)

firmy.m$kolor<-"grey70"
firmy.m$kolor[firmy.m$Freq==1]="red"
firmy.m$kolor[firmy.m$Freq==2]="blue"
firmy.m$kolor[firmy.m$Freq==3]="green"
plot(firmy.m[,12:13], bg=firmy.m$kolor, pch=21)
legend("bottomleft", pch=21, pt.bg=c("grey70", "red", "blue", "green"), c("NA", "wylosowany 1 raz", "wylosowany 2 razy", "wylosowany 3 razy"), bty="n", cex=0.8)

#9.3.2 Możliwości pakietu sperrorest::

# przygotowanie danych obszarowych
crds<-coordinates(pow) # współrzędne geograficzne centroidów
bezrob<-read.csv("bezr2018.csv", header=TRUE, dec=",", sep=";")
bezrob$crds<-crds # dodanie współrzędnych xy do zbioru danych

# przygotowanie wycinka mapy dla danych punktowych
woj.df<-as.data.frame(woj) 
lub.woj<-woj[woj.df$jpt_nazwa_=="lubelskie", ] 

# a-przestrzenny podział danych do walidacji krzyżowej
# podaje się dane i współrzędne geograficzne
# współrzędne nie są uwzględniane w obliczeniach, a jedynie w grafice
library(sperrorest)
bezrob.parti.cv<-partition_cv(bezrob, coords=crds)
plot(bezrob.parti.cv, bezrob, coords=crds) # Rys.9.6a – wybrane punkty
bezrob.parti.cv.dist<-add.distance(bezrob.parti.cv, bezrob, coords=crds)
bezrob.parti.cv.dist[[1]][[1]] # struktura wyniku – pierwsza iteracja

# rysowanie na mapie wybranych obserwacji
resampl<-rep(0, times=dim(bezrob)[1])
resampl[bezrob.parti.cv.dist[[1]][[1]]$test]<-1
zmienna<-as.data.frame(resampl)

# wykres wylosowanych obszarów testowych –Rys.9.6b
library(RColorBrewer)
brks<-c(0, 0.8, 1)
cols=brewer.pal(3,'Blues')
plot(pow, col=cols[findInterval(zmienna$resampl, brks)])
legend("bottomleft", legend=c("training", "test"), fill=cols, cex=0.8, bty="n")
title(main="A-przestrzenny podział do walidacji krzyżowej")

# przygotowanie danych punktowych
firmy<-read.csv("geoloc data.csv", header=TRUE, dec=",", sep=";")
firmy.lim<-firmy[1:500,]

# partycjonowanie punktów Rys.9.7a
library(sperrorest)
firmy.lim.parti.cv<-partition_cv(firmy.lim, coords=c("coords.x1", "coords.x2")) 
plot(firmy.lim.parti.cv, firmy.lim, coords=c("coords.x1", "coords.x2"))

firmy.lim.parti.cv.dist<-add.distance(firmy.lim.parti.cv, firmy.lim, coords =c("coords.x1", "coords.x2"))
firmy.lim.parti.cv.dist[[1]][[1]] # struktura wyniku – pierwsza iteracja

# utworzenie zmiennej zero-jedynkowej
resampl<-rep(0, times=dim(firmy.lim)[1])
resampl[firmy.lim.parti.cv.dist[[1]][[1]]$test]<-1
zmienna<-as.data.frame(resampl)

# wykres wylosowanych punktów testowych – Rys.9.7b
par(mfrow=c(1,1))
cols<-c("coral4","cornflowerblue")
pchset<-c(21,22,23) # wektor symboli dla kolejnych poziomów zmiennej

plot(firmy.lim$coords.x1, firmy.lim$coords.x2, col=cols[factor(zmienna$resampl)], pch=pchset[factor(zmienna$resampl)], cex=1.1, bg=cols[factor(zmienna$resampl)])

plot(lub.woj, add=TRUE)

# podział wg algorytmu k-średnich
bezrob.parti.km<-partition_kmeans(bezrob, coords=crds, nfold=10, order_clusters=FALSE) 
plot(bezrob.parti.km, bezrob, coords=crds) # Rys.9.8a

# utworzenie zmiennej zero-jedynkowej
resampl<-rep(0, times=dim(bezrob)[1])
resampl[bezrob.parti.km[[1]][[1]]$test]<-1
zmienna<-as.data.frame(resampl)

library(RColorBrewer)
brks<-c(0, 0.8, 1) # Rys.9.8b
cols=brewer.pal(3,'Blues')
plot(pow, col=cols[findInterval(zmienna$resampl, brks)], main="Wybór obszarów wg algorytmu k-średnich")
legend("bottomleft", legend=c("training","test"), fill=cols, cex=0.8, bty="n")

# algorytm k-średnich dla danych punktowych – Rys.9.9a
firmy.lim.parti.km<-partition_kmeans(firmy.lim, coords = c("coords.x1", "coords.x2"), nfold=10) 
plot(firmy.lim.parti.km, firmy.lim, coords = c("coords.x1", "coords.x2"))

# utworzenie zmiennej zero-jedynkowej
resampl<-rep(0, times=dim(firmy.lim)[1])
resampl[firmy.lim.parti.km[[1]][[1]]$test]<-1
zmienna<-as.data.frame(resampl)

# Rys.9.9b
cols<-c("coral4","cornflowerblue")
pchset<-c(21,22,23)
plot(firmy.lim$coords.x1, firmy.lim$coords.x2, col=cols[factor(zmienna$resampl)], pch=pchset[factor(zmienna$resampl)], cex=1.1, bg=cols[factor(zmienna$resampl)])
plot(lub.woj, add=TRUE)

#9.3.3 Losowanie punktów z obszarów wyznaczonych algorytmem k-średnich – block bootstrap

# przygotowanie danych
bezrob<-read.csv("bezr2018.csv", header=TRUE, dec=",", sep=";")
crds<-coordinates(pow) # współrzędne geograficzne centroidów
bezrob$crds<-crds # dodanie współrzędnych xy do zbioru danych

n<-dim(bezrob)[1] 	# liczba obserwacji
b<-10 			# średnia długość klastra
k<-n/b 			# liczba klastrów

c1<-kmeans(bezrob$crds, k)	# algorytm k-średnich
bezrob$clust<-c1$cluster 	# wektor klastrujący

library(viridisLite)
#cols<-plasma(k)		# paleta kolorystyczna 
cols<-inferno(k)		# paleta kolorystyczna 
brks<-1:k 			# przedziały

pl<-readOGR(".", "Panstwo") 
pl<-spTransform(pl, CRS("+proj=longlat +datum=NAD83"))

plot(pl) 	# rysowanie mapy
points(bezrob$crds, col=cols[findInterval(bezrob$clust, brks)], 
pch=21, bg=cols[findInterval(bezrob$clust, brks)], cex=2.5)
points(c1$centers, col="red", pch=".", cex=3) # oznaczenie środka klastra
points(c1$centers, col="red", cex=1.5) # oznaczenie środka klastra
title(main="Klastry wg algorytmu k-średnich")

b_emp<-aggregate(bezrob$X2018.05, by=list(bezrob$clust), length)
head(b_emp)

mmax<-max(b_emp$x)
hist(b_emp$x, breaks=1:mmax, ylim=c(0,12), labels=TRUE) # Rys.9.10b
abline(h=(1:6)*2, lty=3)

library(ggplot2) # histogram przy użyciu ggplot::
ggplot(b_emp, aes(x=x)) + geom_histogram(binwidth=1, fill="grey50", color="white")

iter<-100
wynik<-matrix(0, nrow=iter, ncol=4) # do zapisu wyników analiz
colnames(wynik)<-c("unikalne klastry", "długość próby", "unikalne obserwacje", "korelacja")
wybrane<-matrix(0, nrow=k, ncol=iter) # do zapisu składu podpróby

for(i in 1:iter){
ss<-sample(1:k, size=k, replace=TRUE)
wybrane[,i]<-ss # zapis wylosowanych klastrów
wynik[i,1]<-length(unique(ss)) # liczba unikalnych ID

# pusty data.frame
boot1<-data.frame(cluster=numeric(0), var1=numeric(0), var2=numeric(0), crds1=numeric(0), crds2=numeric(0)) 

# doklejenie od dołu bloków obserwacji
for(j in 1:k){
boot1<-rbind(boot1, bezrob[bezrob$clust==ss[j],c(103, 100, 101, 102)])}
wynik[i,2]<-dim(boot1)[1] #długość bootstrapowanej proby
wynik[i,3]<-dim(unique(boot1[,4]))[1] # liczba unikalnych obserwacji
wynik[i,4]<-cor(boot1[,2], boot1[,3]) # korelacja
}

head(wynik)
wybrane[1:6, 1:6]
summary(wynik[,1]/38) # odsetek unikalnych klastrów
summary(wynik[,2]/380) # długość próby względem pełnej próby
summary(wynik[,3]/380) # odsetek unikalnych obserwacji
summary(wynik[,4]/cor(bezrob[,100], bezrob[,101])) # współczynnik korelacji

plot(density(wynik[,4]), main="Rozkład współczynnika korelacji")
abline(v=cor(bezrob[,100], bezrob[,101]), lty=3, col="coral", lwd=2)

plot(density(wynik[,1]/38), xlim=c(0,2), main="Struktura bootstrapowanej próby") # unikalne klastry
lines(density(wynik[,2]/380), lwd=2) # długość próby
lines(density(wynik[,3]/380), lty=3) # unikalne obserwacje
legend(1.10,6,c("unikalne klastry %", "długość próby %", "unikalne obserwacje %"), lty=c(1,1,3), lwd=c(1,2,1), cex=0.8, bty="n")

iter<-100			# liczba iteracji całego modelu
n<-dim(bezrob)[1] 	# liczba obserwacji w zbiorze podstawowym
b<-10 			# średnia długość klastra – długość bloku
k<-n/b 			# liczba klastrów
bezrob$ID<-1:380		# dodanie ID do zbioru podstawowego

wynik<-matrix(0, nrow=iter, ncol=2)
colnames(wynik)<-c("unikalne obserwacje", "korelacja")
wybrane2<-matrix(0, nrow=380, ncol=iter) # obiekt historii losowań

for(i in 1:iter){ # nowe iteracje – powtarzanie badania iter razy
c1<-kmeans(bezrob$crds, k)	# algorytm k-średnich
bezrob$clust<-c1$cluster 	# wektor klastrujący

# pusty data.frame – nowy dla każdej iteracji
boot1<-data.frame(cluster=numeric(0), var1=numeric(0), var2=numeric(0), crds1=numeric(0), crds2=numeric(0), ID=numeric(0)) 

for(m in 1:k){ 	# pętla po wszystkich k klastrach 
sub<-bezrob[bezrob$clust==m,]
ile.obs<-dim(sub)[1] # sprawdzanie długości podzbioru-klastra
ss<-sample(1:ile.obs, size=b, replace=TRUE) # losowanie b obs. z podzbioru

# doklejenie od dołu bloków obserwacji
for(j in 1:b){ # pętla dla każdej obserwacji z danego klastra
boot1<-rbind(boot1, sub[ss[j],c(103, 100, 101, 102, 104)])}}
wybrane2[,i]<-boot1[,5]

wynik[i,1]<-dim(unique(boot1[,4]))[1] # liczba unikalnych obserwacji
wynik[i,2]<-cor(boot1[,2], boot1[,3]) # korelacja
}

ggplot(as.data.frame(wynik), aes(x=wynik[,2])) + geom_density(fill = "lightblue") + geom_vline(xintercept = cor(bezrob[,100], bezrob[,101]), linetype = "dashed") + ggtitle("Rozkład współczynnika korelacji")

ggplot(as.data.frame(wynik), aes(x=wynik[,1]/380)) + geom_density(fill = "lightcoral", alpha=0.8) + ggtitle("Odsetek unikalnych obserwacji")

summary(wynik[,2]/cor(bezrob[,100], bezrob[,101])) # współczynnik korelacji

f1<-as.data.frame(table(wybrane))
head(f1)

library(maptools) # mapa połączony powiatów w bloki
reg.kmeans<-unionSpatialPolygons(pow, IDs= bezrob$clust) #maptools
plot(reg.kmeans, lwd=2) # powiaty połączone wg grupowania k-średnich
plot(pow, add=TRUE)

library(GISTools) # Rys.9.13a
choropleth(reg.kmeans, f1$Freq, main="Częstość wylosowania klastra w 100 iteracjach")
odcienie<-auto.shading(f1$Freq)
choro.legend(14, 50.25, odcienie, cex=0.65, bty="n")

# koordynaty i częstości
p1<-data.frame(crds, z=as.data.frame(table(wybrane2))[,2]) 

bb<-bbox(pl)

library(raster)
r<-raster(nrows=30, ncols=30, ymn=bb[2,1], ymx=bb[2,2], xmn=bb[1,1], xmx=bb[1,2]) # ew. nrows=50, ncols=50
r1<-rasterize(crds, r, field=p1$z, fun=sum)

plot(r1, main="Częstość wylosowanych obserwacji, raster 30x30")
plot(woj, add=TRUE, border="grey80")

#9.3.4 Losowanie punktów z bloków ruchomych (moving block bootstrap)

# przygotowanie danych
bezrob<-read.csv("bezr2018.csv", header=TRUE, dec=",", sep=";")
crds<-coordinates(pow) # współrzędne geograficzne centroidów
bezrob$crds<-crds # dodanie współrzędnych xy do zbioru danych

# wyznaczenie k najbliższych sąsiadów w oparciu o współrzędne
knn.set<-knearneigh(crds, k=9) # macierz k najbliższych sąsiadów
knn.set$`nn` # fragment macierzy knn

# bootstrapowana próba
lead<-sample(1:380, size=38, replace=TRUE) # losowanie głównych punktów
boot<-as.vector(knn.set$`nn`[lead,]) # wektor z wylosowanych sąsiadów
boot2<-c(boot, lead) # złączenie głównych pkt i sąsiadów

length(boot2) # długość łączna zbioru wylosowanych ID
length(unique(boot2)) # liczba unikalnych identyfikatorów ID

# przepisanie wylosowanych wartości z pełnego zbioru danych wg nowych ID
# badane zmienne w kolumnach 100:101
boot3<-matrix(0, nrow=380, ncol=2)
for(i in 1:380){
boot3[i,1:2]<-as.numeric(bezrob[boot2[i], 100:101])}

cor(boot3[,1], boot3[,2]) # korelacja w bootstrapowanej próbie
a<-cor(bezrob[,100], bezrob[,101]) # korelacja w pełnej próbie
a

vec<-(20:1)*5/100
#[1] 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.55 0.50 0.45 0.40
#[14] 0.35 0.30 0.25 0.20 0.15 0.10 0.05
b=10 	# długość bloku (ew. b=20)
knn.set<-knearneigh(crds, k=b-1) # macierz k najbliższych sąsiadów

wynik<-matrix(0, nrow=30, ncol=20)
colnames(wynik)<-paste(rep("cov", times=20), vec)
rownames(wynik)<-paste(rep("iter", times=30),1:30)

for(i in 1:20){ # poziomy pokrycia – kolumny wyniku
ile<-380*vec[i] # liczba obserwacji łącznie do wylosowania

for(j in 1:30){ # iteracje dla każdego poziomu pokrycia – wiersze wyniku
lead<-sample(1:380, size= ceiling(ile/b), replace=TRUE) # ew. replace=FALSE
boot<-as.vector(knn.set$`nn`[lead,]) # wektor z wylosowanych sąsiadów
boot2<-c(boot, lead) # złączenie głównych pkt i sąsiadów
boot3<-matrix(0, nrow=ile, ncol=2)
for(k in 1:ile){
boot3[k,1:2]<-as.numeric(bezrob[boot2[k], 100:101])}
wynik[j,i]<-cor(boot3[,1], boot3[,2])}} # korelacja
wynik[1:6, 1:6]

śr<-as.vector(apply(wynik, 2, mean))
sd<-as.vector(apply(wynik, 2, sd))
data<-as.data.frame(cbind(śr, sd))
colnames(data)<-c("śr", "sd")
data$lower<-data$śr-data$sd
data$upper<-data$śr+data$sd
data$model<-rep("block10", times=20) #ew. block20
data$interval<-(20:1)*5/100

data1<-data
data11<-rbind(data, data1)

library(ggplot2)
p<-ggplot(data=data11, aes(x=interval, y=śr, colour=model)) + geom_point() + geom_line() 
p<-p+ geom_ribbon(aes(ymin=data11$lower, ymax=data11$upper), linetype=2, alpha=0.1) + xlab("pokrycie próby") + ylab("średnia korelacja")
p<-p+ geom_hline(yintercept=a, linetype="dashed") + ggtitle("MBB dla b=10")
plot(p) # Rys.9.14a

# losowanie proste
wynik2<-matrix(0, nrow=30, ncol=20)
colnames(wynik2)<-paste(rep("cov", times=20), vec)
rownames(wynik2)<-paste(rep("iter", times=30),1:30)

for(i in 1:20){ # poziomy pokrycia – kolumny wyniku
ile<-380*vec[i] # liczba obserwacji łącznie do wylosowania

for(j in 1:30){ # iteracje dla każdego poziomu pokrycia – wiersze wyniku
lead<-sample(1:380, size= ile, replace=TRUE) # ew. replace=FALSE
boot3<-matrix(0, nrow=ile, ncol=2)
for(k in 1:ile){
boot3[k,1:2]<-as.numeric(bezrob[lead[k], 100:101])}
wynik2[j,i]<-cor(boot3[,1], boot3[,2])}} # korelacja

śr2<-as.vector(apply(wynik2, 2, mean))
sd2<-as.vector(apply(wynik2, 2, sd))
data2<-as.data.frame(cbind(śr2, sd2))
colnames(data2)<-c("śr", "sd")
data2$lower<-data2$śr-data2$sd
data2$upper<-data2$śr+data2$sd
data2$model<-rep("simple", times=20)
data2$interval<-(20:1)*5/100

data3<-rbind(data, data2) # złączenie wyników MBB I CR
# wspólny wykres MMB i CR – dzięki opcji colour w aes
p<-ggplot(data=data3, aes(x=interval, y=śr, colour=model)) + geom_point() + geom_line()
p<-p+geom_ribbon(aes(ymin=data3$lower, ymax=data3$upper), linetype=2, alpha=0.1) + xlab("pokrycie próby") + ylab("średnia korelacja")
plot(p) # Rys.9.15b

#9.4. Wykorzystanie próbkowania przestrzennego i bootstrap w walidacji krzyżowej modeli 

# wybór zmiennych 
bezrob_ml<-bezrob[, c(13:101)] # podzbiór danych dedykowany do analizy
crds_ml<-bezrob$crds

# imputacja brakujących danych 
bezrob_ml[c(248, 286, 344, 359), 1]<-c(631188, 123659, 119171, 102422)

# dołączenie współrzędnych geograficznych do zbioru danych
bezrob_ml$x<-crds[,1]
bezrob_ml$y<-crds[,2]

# formuła równania
RHS<-paste(names(bezrob_ml)[-90], collapse='+') 
LHS<-names(bezrob_ml)[90]

wzor_ml<-as.formula(paste0(LHS, '~', RHS))
wzor_ml

# dodanie zmiennej „województwo” do zbioru danych
bezrob_ml$woj<-bezrob$województwo

library(randomForest) # wczytanie pakietu
set.seed(1234) # Ustawienie ziarna losowania

# oszacowanie modelu
model<-randomForest(wzor_ml, data=bezrob_ml, ntree=500)
model # wydruk wyników
# wykres dopasowania modelu do danych
plot(model) # wykres 9.21
# przykładowe losowanie punktów
library(sperrorest)
resamp<-partition_cv(bezrob_ml, nfold=5, repetition=1, seed1=1)
plot(resamp, bezrob_ml, coords = c("x","y")) # Rys.9.17a

res_rf_cv<-sperrorest(wzor_ml, 	# wzór funkcji
   	data = bezrob_ml, 		# baza danych
   model_fun = randomForest, 		# nazwa funkcji
   model_args = list(ntree = 50, 	# liczba drzew 
mtry = 90), 	# liczba zmiennych
   smp_fun = partition_cv, 		# funkcja próbkująca
   smp_args=list(repetition = 100, 	# liczba powtórzeń
nfold = 5, 		# liczba foldów
seed1 = 1234), 	# ziarno losowania
err_fun=err_default, #funkcja zwracająca statysyki dopasowania
   error_rep = TRUE, 			# zapisanie błędów w każdym powt.
   progress = 'all') 			# wydruk postępu w obliczeniach
round(summary(res_rf_cv$error_rep), 3) # wydruk wyników

# zbiór z przykładową próbką danych
df<-data.frame(prop=c(round(prop.table(table(bezrob_ml$woj)), 2), round(prop.table(table( bezrob_ml$woj[resamp$`1`$`3`$train])), 2)),
labels=c(rep('cała próba (380 powiatów)', 16), rep('Przykładowy zbiór treningowy', 16)), woj = c(names(table(bezrob_ml$woj)), names(table(bezrob_ml$woj))))

# wygenerowanie rys.9.18 
Library(ggplot2)
ggplot(data=df, aes(x=woj, y=prop, fill=labels)) + 
  geom_col(position='dodge') + xlab(NULL) + 
  theme(axis.text.x = element_text(angle=45, hjust=1, size=7),   legend.position='bottom', legend.title=element_blank()) +
 scale_y_continuous(labels=scales::percent, name='Częstość')

# wygenerowanie przykładowych foldów dla samplingu stratyfikowanego
resamp<-partition_cv_strat(bezrob_ml, nfold=5, repetition=1, seed1=1234, strat='woj')

plot(resamp, bezrob_ml, coords = c("x","y")) # rys.9.22b

# przygotowanie danych do rys.9.19
df<-data.frame(prop=c(round(prop.table(table(bezrob_ml$woj)), 2), round(prop.table(table(bezrob_ml$woj[resamp$`1`$`3`$train])), 2)),
labels=c(rep('cała próba (380 powiatów)', 16), rep('Przykładowy zbiór treningowy', 16)),
woj=c(names(table(bezrob_ml$woj)), names(table(bezrob_ml$woj))))

# rys.9.19
ggplot(data = df, aes(x = woj, y = prop, fill = labels)) +
geom_col(position = 'dodge') + xlab(NULL) +
theme(axis.text.x = element_text(angle = 45, hjust = 1, size = 10),
legend.position = 'bottom', legend.title = element_blank()) +
scale_y_continuous(labels = scales::percent, name = 'Częstość')
set.seed(1234)
res_rf_strat<-sperrorest(wzor_ml, 	# wzór funkcji
   data = bezrob_ml, 			# baza danych
   model_fun = randomForest, 		# nazwa funkcji
   model_args = list(ntree = 50, 	# liczba drzew 
   mtry = 90), 				# liczba zmiennych
   smp_fun = partition_cv_strat, 	# funkcja próbkująca
   smp_args=list(repetition=100, nfold=5, seed1=1234, strat='woj'),
   error_rep = TRUE, 			# zapisanie błędów w każdym powtórzeniu
   Progres = 'all') 			# wydruk postępu w obliczeniach

round(summary(res_rf_strat$error_rep), 3) # Wydruk wyników

# losowanie oparte na k-średnich
resamp <- partition_kmeans(bezrob_ml, nfold = 5, coords = c('x', 'y'),
      repetition = 1, seed1 = 1234)
plot(resamp, bezrob_ml, coords = c("x","y")) # rys.9.22c

set.seed(1234)
res_rf_kmeans<-sperrorest(wzor_ml, data=bezrob_ml, model_fun=randomForest, model_args=list(ntree=50, mtry=90), smp_fun=partition_kmeans, Progres='all', smp_args=list(repetition=100, nfold=5, seed1=1234), error_rep=TRUE) 	
round(summary(res_rf_kmeans$error_rep), 3) # Wydruk wyników

# Sampling czynnikowy
resamp <- partition_factor_cv(bezrob_ml, nfold = 5, fac = 'woj', coords = c('x', 'y'), repetition = 1, seed1 = 1234)

# Rys.9.22d
plot(resamp, bezrob_ml, coords = c("x","y"))

res_rf_factor<-sperrorest(wzor_ml, data=bezrob_ml, model_fun=randomForest, model_args=list(ntree=50, mtry=90), smp_fun=partition_factor_cv, Progres='all', smp_args=list(repetition=100, nfold=5, fac='woj', seed1=1234), error_rep=TRUE) 	
round(summary(res_rf_factor$error_rep), 3) # wydruk wyników

res_rf_ti<-sperrorest(wzor_ml, data=bezrob_ml, coords=c("x","y"), model_fun=randomForest, model_args=list(ntree=50, mtry=90), smp_fun=partition_tiles, smp_args=list(repetition=100, seed1=1234, nsplit=c(3, 2)), error_rep=TRUE, error_fold=TRUE, progress='all') 	
round(summary(res_rf_ti$error_rep), 3) # wydruk wyników

# Las losowy z losowaniem z k-średnich
resamp <- partition_kmeans(bezrob_ml, nfold = 5, coords = c('x', 'y'),
      repetition = 1, seed1 = 1234)
set.seed(1234)
res_rf_km <- sperrorest(wzor_ml, 	# wzór funkcji
    data = bezrob_ml, 			# baza danych
    coords = c("x","y"), 		#koordynaty (tutaj ignorowane)
    model_fun = randomForest, 	# nazwa funkcji
    model_args = list(ntree = 50, 	# liczba drzew
       mtry = 90), 			# liczba zmiennych 
    smp_fun = partition_kmeans, 	# funkcja próbkująca
    smp_args = list(repetition = 100, #liczba powtórzeń
        nfold = 5, 			# liczba foldów
        seed1 = 1234),			# ziarno losowania
    error_rep = TRUE, 			# zapis błędu z każdego powt.
    error_fold = TRUE, 			# zapis błędu z każdego foldu
    progress = 'all') 			# wydruk postępu w obliczeniach

# Las losowy z losowaniem czynnikowym
resamp <- partition_factor_cv(bezrob_ml, nfold = 5, fac = 'woj', 
     coords = c('x', 'y'), repetition = 1, seed1 = 1234)
set.seed(1234)
res_rf_fa <- sperrorest(wzor_ml, 	# wzór funkcji
    data = bezrob_ml, 			# baza danych
    coords = c("x","y"), 		# koordynaty (tutaj ignorowane)
    model_fun = randomForest, 	# nazwa funkcji
    model_args = list(ntree = 50, 	# liczba drzew
       mtry = 90), 			# liczba zmiennych 
    smp_fun = partition_factor_cv, 	# funkcja próbkująca
    smp_args = list(repetition = 100, #liczba powtórzeń
        nfold = 5, 			# liczba foldów
        seed1 = 1234),			# ziarno losowania
    error_rep = TRUE, 			# zapis błędu z każdego powt.
    error_fold = TRUE, 			# zapis błędu z każdego foldu
    progress = 'all') 			# wydruk postępu w obliczeniach

# Las losowy z próbkowaniem z kafli
resamp <- partition_tiles(bezrob_ml, nsplit = c(3, 2), 
     coords = c('x', 'y'), repetition = 1)
set.seed(1234)
res_rf_ti <- sperrorest(wzor_ml, 	# wzór funkcji
    data = bezrob_ml, 			# baza danych
    coords = c("x","y"), 		#koordynaty (tutaj ignorowane)
    model_fun = randomForest, 	# nazwa funkcji
    model_args = list(ntree = 50, 	# liczba drzew
       mtry = 90), 			# liczba zmiennych 
    smp_fun = partition_tiles, 	# funkcja próbkująca
    smp_args = list(repetition = 100, #liczba powtórzeń
        nfold = 5, 			# liczba foldów
        seed1 = 1234),			# ziarno losowania
    error_rep = TRUE, 			# zapis błędu z każdego powt.
    error_fold = TRUE, 			# zapis błędu z każdego foldu
    progress = 'all') 			# wydruk postępu w obliczeniach

# Przygotowanie danych ze zbiorczymi wynikami.
df <- data.frame(cv = res_rf_cv$error_rep$test_rmse, 
   strat = res_rf_strat$error_rep$test_rmse,
   factor = res_rf_fa$error_rep$test_rmse,
   kmeans = res_rf_km$error_rep$test_rmse,
   tile = res_rf_ti$error_rep$test_rmse)

# Wykres 9.29.
ggplot(data=df) +
 stat_density(aes(x=cv, color='Klasyczna CV'), geom='line') +
 geom_vline(aes(xintercept=mean(cv), color='Klasyczna CV'), linetype= 'dashed') +
 stat_density(aes(x=strat, color='Stratyfikowana CV'), geom='line') + geom_vline(aes(xintercept=mean(strat), color='Stratyfikowana CV'), linetype ='dashed') +
 stat_density(aes(x=factor, color='Czynnikowa CV'), geom='line') +
 geom_vline(aes(xintercept=mean(factor), color='Czynnikowa CV'), linetype ='dashed') +
 stat_density(aes(x=kmeans, color='kmeans CV'), geom='line') +
 geom_vline(aes(xintercept=mean(kmeans), color='kmeans CV'), linetype = 'dashed') +
 stat_density(aes(x=tile, color='tiles CV'), geom='line') +
 geom_vline(aes(xintercept=mean(tile), color='tiles CV'), linetype = 'dashed') +
 theme(legend.position='bottom', legend.title=element_blank())



