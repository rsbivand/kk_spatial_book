##############################################
#Applied Spatial Statistics and Econometrics: Data Analysis in R (Routledge, 2020) 
#Przestrzenne metody ilościowe w R: statystyka, ekonometria, uczenie maszynowe, analiza danych (CeDeWu, 2020)
#Editor: Katarzyna Kopczewska 
#Authors: Katarzyna Kopczewska, Maria Kubara, Piotr Ćwiakowski, Mateusz Kopyt, Piotr Wójcik, Alessandro Festi, Kateryna Zabarina
#This book is a part of project supported by the Polish National Science Center (NCN) on „Spatial econometric models with fixed and changing neighborhood structure. Application for real estate valuation and business location” (OPUS 12, contract no. UMO-2016/23/B/ HS4/02363).
#All sample data used in the book and the codes presented in the content of the book were placed on https://github.com/kkopczewska/spatial_book 
##############################################

#Chapter 9
#Spatial sampling and bootstrapping
#Katarzyna Kopczewska, orcid.org/0000-0003-1065-1790
#Piotr Ćwiakowski, orcid.org/0000-0003-3181-7227

#9.1 Spatial point data - object classes and spatial aggregation

# point data set - 5000 observations
firms<-read.csv("geoloc_data_firms.csv", header=TRUE, dec=",", sep=";")
firms.lim<-firms[1:5000,]

#reminder – reading spatial objects
voi<-readOGR(".", "wojewodztwa") # 16 units 
voi<-spTransform(voi, CRS("+proj=longlat +datum=NAD83"))

pov<-readOGR(".", "powiaty") # 380 units
pov<-spTransform(pov, CRS("+proj=longlat +datum=NAD83"))

#reminder – creating subsets for lubelskie region
voi.df<-as.data.frame(voi)
lub.voi<-voi[voi.df$jpt_nazwa_=="lubelskie", ]
data<-read.csv("data_nts4_2019.csv", header=TRUE, dec=",", sep=";")
data15<-data[data$year==2015, ]
lub.pov<-pov[data15$region_name=="Lubelskie", ]

# Fig.9.1a – subset of map (see Chapter 2) and point data
plot(lub.voi, lwd=2) # subset of the provincial map created earlier
plot(lub.pov, add=TRUE) # subset of the poviat map 
points(firms.lim[,12:13], pch=".") # locations xy points 

# change the point data class from data.frame to SpatialPoints
firms.lim.sp<-SpatialPoints(firms.lim[,12:13], proj4string=CRS(proj4string(lub.pov)))

pts<-over(firms.lim.sp, lub.pov) # affiliation of points to areas
pts.ag<-aggregate(pts$jpt_nazwa_, by=list(pts$jpt_nazwa_), length)
head(pts.ag)

# horizontal bar chart of aggregated data
par(mar=c(2,10,2,2)) # order of margins: bottom, left, top, right
barplot(pts.ag$x, horiz=TRUE, names.arg=pts.ag$Group.1, las=1, xlim=c(0,700))
abline(v=(1:7)*100, lty=3)
par(mar=c(2,2,2,2))

library(spatstat)
library(rgdal)
library(maptools) # necessary to run as.owin() or as(*, "owin")
# change of contour projection
lub.pov<-spTransform(lub.pov, CRS("+proj=merc +datum=NAD83")) # planar
lub.pov.owin<-as(lub.pov, "owin") # conversion of SpatialPolygon to owin

# change of points projection
proj4string(firms.lim.sp)<-CRS("+proj=longlat +datum=NAD83") # spherical
firms.lim.sp<-spTransform(firms.lim.sp, CRS("+proj=merc +datum=NAD83")) 

# ppp object – without marks and with marks
firms.lim.ppp<-ppp(firms.lim.sp@coords[,1],  firms.lim.sp@coords[,2],  window=lub.pov.owin)
firms.lim.ppp.m<-ppp(firms.lim.sp@coords[,1],  firms.lim.sp@coords[,2],  window=lub.pov.owin, marks=firms.lim[,18])

# points diagram (ppp class) - location and value in point
plot(firms.lim.ppp) # points diagram (ppp class) - location only, fig.9.1a
plot(firms.lim.ppp.m, cex=0.8, border="red") #locations & values, fig.9.1b

#9.2 Spatial sampling - randomization / generation of new points on the surface

# creation of a map section - voivodship (NTS2) Lubelskie, Fig.9.2
voi.df<-as.data.frame(voi) 
lub.voi<-voi[voi.df$jpt_nazwa_=="lubelskie", ] 

# randomly drawn points - regular distribution
plot(lub.voi, main="Regular dots in Lubelskie NTS2")
points(spsample(lub.voi, n=1000, "regular"), pch=".", cex=2)

# randomly drawn points - random distribution
plot(lub.voi, main="Random dots in Lubelskie NTS2")
points(spsample(lub.voi, n=1000, "random"), pch=".", cex=2)

# randomly drawn points - stratified drawing
plot(lub.voi, main="Stratified dots in Lubelskie NTS2")
points(spsample(lub.voi, n=1000, "stratified"), pch=".", cex=2)

# randomly drawn points - non-aligned drawing
plot(lub.voi, main="Nonaligned dots in Lubelskie NTS2")
points(spsample(lub.voi, n=1000, "nonaligned"), pch=".", cex=2)

# randomly drawn points - hexagonal distribution
plot(lub.voi, main="Hexagonal dots in Lubelskie NTS2")
points(spsample(lub.voi, n=1000, "hexagonal"), pch=".", cex=2)

# randomly drawn points - clustered distribution
plot(lub.voi, main="Clustered dots in Lubelskie NTS2")
points(spsample(lub.voi, n=1000, "clustered"), pch=".", cex=2)

# Figure – random points - the whole multi-regional map
plot(voi, main="Random dots in Poland (16 regions)")
points(spsample(voi, n=2000, "random"), pch=".", cex=2)

# Figure - random points – one region from a multi-regional map
plot(voi, main="Random dots in selected region (1 out of 16)")
points(spsample(voi@polygons[[1]], n=200, "random"), pch=".", cex=2)

lub.voi<-spTransform(lub.voi, CRS("+proj=merc +datum=NAD83")) # planar
lub.voi.owin<-as(lub.voi, "owin") # conversion SpatialPolygon to owin

# stratified sampling, with background divided into tiles
r1<-rstrat(win=lub.voi.owin, nx=10, ny=10, k=5)
plot(r1, main="66 tiles, k = 5 observations in the tile ")

r2<-rstrat(win=lub.pov.owin, nx=15, ny=15, k=3)
plot(r2, main="431 tiles, k = 3 observations in the tile ")

# generating points evenly distributed in space
r3<-rsyst(win=lub.voi.owin, nx=10, ny=10) 
plot(r3, main="63 regular points") # regular points and regional contour

r4<-rsyst(win=lub.pov.owin, nx=15, ny=15)
plot(r4, main="140 regular points") # regular points and poviat contours

#9.3 Spatial sampling - sampling of sub-samples from existing points
#9.3.1 Simple sampling

#firms.lim<-firms[1:5000,] # reminder of the data set
result<-matrix(0, nrow=50, ncol=30)
for(i in 1:30){
result[,i]<-sample(1:5000, size=50, replace=TRUE)}
result [1:5, 1:5] # the result of the ID draw
a1<-as.data.frame(table(result))
head(a1)

firms.lim$ID<-1:5000
firms.m<-merge(firms.lim, a1, by.x="ID", by.y="result", all.x=TRUE)

firms.m$color<-"grey70"
firms.m$color[firms.m$Freq==1]="red"
firms.m$color[firms.m$Freq==2]="blue"
firms.m$color[firms.m$Freq==3]="green"
plot(firms.m[,12:13], bg= firms.m$color, pch=21) # Fig.9.3
legend("bottomleft", pch=21, pt.bg=c("grey70", "red", "blue", "green"), c("NA", "drawn 1 time", "drawn 2 times", "drawn 3 times"), bty="n", cex=0.8)

#9.3.2 The options of the sperrorest:: package

# preparation of area data 
crds<-coordinates(pov) # geographical coordinates of centroids
unempl<-read.csv("unemp2018.csv", header=TRUE, dec=",", sep=";")
unempl$crds<-crds # adding xy coordinates to the data set

# preparation of a map section for point data
voi.df<-as.data.frame(voi) 
lub.voi<-voi[voi.df$jpt_nazwa_=="lubelskie", ] 

# a-spatial division of data for cross-validation
# data and geographical coordinates are given
# coordinates are not included in the calculations, only in the graphics
library(sperrorest)
unempl.parti.cv<-partition_cv(unempl, coords=crds)
plot(unempl.parti.cv, unempl, coords=crds) # Fig.9.4a - selected points
unempl.parti.cv.dist<-add.distance(unempl.parti.cv, unempl, coords=crds)
unempl.parti.cv.dist[[1]][[1]] # structure of result - first iteration

# drawing selected observations on the map
resampl<-rep(0, times=dim(unempl)[1])
resampl[unempl.parti.cv.dist[[1]][[1]]$test]<-1
variable <-as.data.frame(resampl)

# chart of selected test areas – Fig.9.4b
library(RColorBrewer)
brks<-c(0, 0.8, 1)
cols=brewer.pal(3,'Blues')
plot(pov, col=cols[findInterval(variable$resampl, brks)])
legend("bottomleft", legend=c("training", "test"), fill=cols, cex=0.8, bty="n")
title(main="A-spatial division for cross-validation")

# preparation of point data
firms<-read.csv("geoloc_data_firms.csv", header=TRUE, dec=",", sep=";")
firms.lim<-firms[1:500,]

# a-spatial partitioning of points Fig.9.5a
firms.lim.parti.cv<-partition_cv(firms.lim, coords=c("coords.x1", "coords.x2"))  
plot(firms.lim.parti.cv, firms.lim, coords=c("coords.x1", "coords.x2"))

firms.lim.parti.cv.dist<-add.distance(firms.lim.parti.cv, firms.lim, coords =c("coords.x1", "coords.x2"))
firms.lim.parti.cv.dist[[1]][[1]] # structure of result - first iteration

# creation of a dummy variable
resampl<-rep(0, times=dim(firms.lim)[1])
resampl[firms.lim.parti.cv.dist[[1]][[1]]$test]<-1
variable<-as.data.frame(resampl)

# chart of randomly selected test points - Fig.9.5b
par(mfrow=c(1,1))
cols<-c("coral4","cornflowerblue")
pchset<-c(21,22,23) # vector symbols for subsequent levels of a variable

plot(firms.lim$coords.x1, firms.lim$coords.x2, col=cols[factor(variable$resampl)], pch=pchset[factor(variable$resampl)], cex=1.1, bg=cols[factor(variable$resampl)])

plot(lub.voi, add=TRUE)

# division according to the k-means algorithm
unempl.parti.km<-partition_kmeans(unempl, coords=crds, nfold=10, order_clusters=FALSE)  
plot(unempl.parti.km, unempl, coords=crds)

# creation of a dummy variable
resampl<-rep(0, times=dim(unempl)[1])
resampl[unempl.parti.km[[1]][[1]]$test]<-1
variable<-as.data.frame(resampl)

brks<-c(0, 0.8, 1) 
cols=brewer.pal(3,'Blues')
plot(pov, col=cols[findInterval(variable$resampl, brks)], main="Selection of areas according to the k-means algorithm")
legend("bottomleft", legend=c("training","test"), fill=cols, cex=0.8, bty="n")

# k-means algorithm for point data
firms.lim.parti.km<-partition_kmeans(firms.lim, coords=c("coords.x1", "coords.x2"), nfold=10)  
plot(firms.lim.parti.km, firms.lim, coords=c("coords.x1", "coords.x2"))

# creation of a dummy variable
resampl<-rep(0, times=dim(firms.lim)[1])
resampl[firms.lim.parti.km.dist[[1]][[1]]$test]<-1
variable<-as.data.frame(resampl)

# map of points locations with colours reflecting partitions
cols<-c("coral4","cornflowerblue")
pchset<-c(21,22,23)
plot(firms.lim$coords.x1, firms.lim$coords.x2, col=cols[factor(variable$resampl)], pch=pchset[factor(variable$resampl)], cex=1.1, bg=cols[factor(variable$resampl)])
plot(lub.voi, add=TRUE)

#9.3.3 Sampling points from areas determined by the k-means algorithm - block bootstrap

# data preparation
unempl<-read.csv("unemp2018.csv", header=TRUE, dec=",", sep=";")
crds<-coordinates(pov) # geographical coordinates of centroids
unempl$crds<-crds # adding xy coordinates to the data set

n<-dim(unempl)[1] 	# number of observations
b<-10 			# average cluster length
k<-n/b 			# the number of clusters

c1<-kmeans(unempl$crds, k)	# k-means algorithm
unempl$clust<-c1$cluster 	# clustering vector

library(viridisLite)
#cols<-plasma(k)		# color palette 
cols<-inferno(k)		# color palette 
brks<-1:k 			# intervals

pl<-readOGR(".", "Panstwo") 
pl<-spTransform(pl, CRS("+proj=longlat +datum=NAD83"))

plot(pl) 	# drawing a map, Fig.9.6a 
points(unempl$crds, col=cols[findInterval(unempl$clust, brks)], 
pch=21, bg=cols[findInterval(unempl$clust, brks)], cex=2.5)
points(c1$centers, col="red", pch=".", cex=3) # plot of cluster centres
points(c1$centers, col="red", cex=1.5) # plot of cluster centers
title(main="Clusters according to the k-average algorithm")

b_emp<-aggregate(unempl$X2018.05, by=list(unempl$clust), length)
head(b_emp)

mmax<-max(b_emp$x) # Fig.9.6b
hist(b_emp$x, breaks=1:mmax, ylim=c(0,12), labels=TRUE, col="orange") 
abline(h=(1:6)*2, lty=3)

library(ggplot2) # alternative graphics
ggplot(b_emp, aes(x=x)) + geom_histogram(binwidth=1, fill="grey50", color="white")

iter<-100
result<-matrix(0, nrow=iter, ncol=4) # to write the results of analysis
colnames(result)<-c("unique clusters", "sample length", "unique observations", "correlation")
selected<-matrix(0, nrow=k, ncol=iter) # empty object to save results

for(i in 1:iter){
ss<-sample(1:k, size=k, replace=TRUE)
selected[,i]<-ss # record of randomly drawn clusters
result[i,1]<-length(unique(ss)) # number of unique IDs

# empty data.frame
boot1<-data.frame(cluster=numeric(0), var1=numeric(0), var2=numeric(0), crds1=numeric(0), crds2=numeric(0)) 

# appending from the bottom of the blocks of observation
for(j in 1:k){
boot1<-rbind(boot1, unempl[unempl$clust==ss[j],c(103, 100, 101, 102)])}
result[i,2]<-dim(boot1)[1] # length of bootstrapped sample
result[i,3]<-dim(unique(boot1[,4]))[1] # number of unique observations
result[i,4]<-cor(boot1[,2], boot1[,3]) # correlation
}

head(result)
selected[1:6, 1:6]
summary(result[,1]/38) # the percentage of unique clusters
summary(result[,2]/380) # length of the trial relative to the full sample
summary(result[,3]/380) # the percentage of unique observations

# correlation coefficient
summary(result[,4]/cor(unempl[,100], unempl[,101])) 

plot(density(result[,4]), main="Distribution of the correlation coefficient") #Fig.9.7a
abline(v=cor(unempl[,100], unempl[,101]), lty=3, col="coral", lwd=2)

plot(density(result[,1]/38), xlim=c(0,2), main="Structure of the bootstrapped sample") # unique clusters, Fig.9.7b
lines(density(result[,2]/380), lwd=2) # the length of the trial
lines(density(result[,3]/380), lty=3) # unique observations
legend(1.10,6,c("unique clusters%", "sample length%", "unique observations%"), lty=c(1,1,3), lwd=c(1,2,1), cex=0.8, bty="n")

iter<-100			# the number of iterations of the entire model
n<-dim(unempl)[1] 	# number of observations in the basic set
b<-10 			# average cluster length - block length
k<-n/b 			# the number of clusters
unempl$ID<-1:380		# adding ID to the basic file

result<-matrix(0, nrow=iter, ncol=2)
colnames(result)<-c("unique observations", "correlation")
selected2<-matrix(0, nrow=380, ncol=iter) # object of history of draws

for(i in 1:iter){ # new iterations - repeating the test iter times
c1<-kmeans(unempl$crds, k)	# k-means algorithm
unempl$clust<-c1$cluster 	# clustering vector

# empty data.frame – new for each iteration
boot1<-data.frame(cluster=numeric(0), var1=numeric(0), var2=numeric(0), crds1=numeric(0), crds2=numeric(0), ID=numeric(0)) 

for(m in 1:k){ 	# loop after all k clusters
sub<-unempl[unempl$clust==m,]
ile.obs<-dim(sub)[1] # checking the subset length – of cluster
ss<-sample(1:ile.obs, size=b, replace=TRUE) # drawing b obs. from a subset

# appending from the bottom of the blocks of observation
for(j in 1:b){ # a loop for each observation from a given cluster
boot1<-rbind(boot1, sub[ss[j],c(103, 100, 101, 102, 104)])}}
selected2[,i]<-boot1[,5]

result[i,1]<-dim(unique(boot1[,4]))[1] # number of unique observations
result[i,2]<-cor(boot1[,2], boot1[,3])} # correlation

# Fig.9.8a
ggplot(as.data.frame(result), aes(x=result[,2])) + geom_density(fill = "lightblue") + geom_vline(xintercept = cor(unempl[,100], unempl[,101]), linetype = "dashed") + ggtitle("Distribution of the correlation coefficient")

# Fig.9.8b
ggplot(as.data.frame(result), aes(x=result[,1]/380)) + geom_density(fill = "lightcoral", alpha=0.8) + ggtitle("Percentage of unique observations")

summary(result[,2]/cor(unempl[,100], unempl[,101])) # correlation coefficient

f1<-as.data.frame(table(selected))
head(f1)

library(maptools) 
reg.kmeans<-unionSpatialPolygons(pov, IDs= unempl$clust) #maptools
plot(reg.kmeans, lwd=2) # poviats combined by grouping k-means
plot(pov, add=TRUE)

library(GISTools) # Fig.9.9a
choropleth(reg.kmeans, f1$Freq, main="Frequency of drawing given cluster in 100 iterations")
shades <-auto.shading(f1$Freq)
choro.legend(14, 50.25, shades, cex=0.65, bty="n")

# coordinates and frequency
p1<-data.frame(crds, z=as.data.frame(table(selected2))[,2]) 
bb<-bbox(pl)

library(raster)
r<-raster(nrows=30, ncols=30, ymn=bb[2,1], ymx=bb[2,2], xmn=bb[1,1], xmx=bb[1,2]) # Fig.9.9b
r1<-rasterize(crds, r, field=p1$z, fun=sum)
plot(r1, main="The frequency of drawn observations, raster 30x30")
plot(voi, add=TRUE, border="grey80")

#9.3.4 Sampling points from moving blocks (moving block bootstrap, MBB)

# data preparation
unempl<-read.csv("unemp2018.csv", header=TRUE, dec=",", sep=";")
crds<-coordinates(pov) # geographical coordinates of centroids
unempl$crds<-crds # adding xy coordinates to the data set

# determining k nearest neighbors based on coordinates
knn.set<-knearneigh(crds, k=9) # matrix k nearest neighbors
knn.set$`nn` # fragment of the knn matrix

# bootstrapped trials
lead<-sample(1:380, size=38, replace=TRUE) # drawing of main points
boot<-as.vector(knn.set$`nn`[lead,]) # vector from randomly drawn neighbors
boot2<-c(boot, lead) # joining the main points and neighbors

length(boot2) # total length of the drawn IDs
length(unique(boot2)) # number of unique IDs

# rewriting the drawn values from the complete data set according to the new ID
# studied variables in columns 100: 101
boot3<-matrix(0, nrow=380, ncol=2)
for(i in 1:380){
boot3[i,1:2]<-as.numeric(unempl[boot2[i], 100:101])}

cor(boot3[,1], boot3[,2]) # correlation in the bootstrapped sample
a<-cor(unempl[,100], unempl[,101]) # correlation in the full sample 
a

vec<-(20:1)*5/100
#[1] 1.00 0.95 0.90 0.85 0.80 0.75 0.70 0.65 0.60 0.55 0.50 0.45 0.40
#[14] 0.35 0.30 0.25 0.20 0.15 0.10 0.05
b=20 	# block length (possibly b = 20)
knn.set<-knearneigh(crds, k=b-1) # matrix k nearest neighbors

result<-matrix(0, nrow=30, ncol=20)
colnames(result)<-paste(rep("cov", times=20), vec)
rownames(result)<-paste(rep("iter", times=30),1:30)

for(i in 1:20){ # coverage levels - result columns
samp.size<-380*vec[i] # the total number of observations to be drawn

for(j in 1:30){ # iterations for each coverage level - result rows
lead<-sample(1:380, size=ceiling(samp.size/b), replace=TRUE) 
boot<-as.vector(knn.set$`nn`[lead,]) # vector from randomly drawn neighbors
boot2<-c(boot, lead) # joining the main points and neighbors
boot3<-matrix(0, nrow=samp.size, ncol=2)
for(k in 1:samp.size){
boot3[k,1:2]<-as.numeric(unempl[boot2[k], 100:101])}
result[j,i]<-cor(boot3[,1], boot3[,2])}} # correlation
result[1:6, 1:6]

mea<-as.vector(apply(result, 2, mean))
sd<-as.vector(apply(result, 2, sd))
data<-as.data.frame(cbind(mea, sd))
colnames(data)<-c("mea", "sd")
data$lower<-data$mea-data$sd
data$upper<-data$mea+data$sd
data$model<-rep("block20", times=20) #also: block20
data$interval<-(20:1)*5/100

data1<-data
data11<-rbind(data, data1)

library(ggplot2)

# Fig.9.10a
p<-ggplot(data=data11, aes(x=interval, y=mea, colour=model)) + geom_point() + geom_line() 
p<-p + geom_ribbon(aes(ymin=data11$lower, ymax=data11$upper), linetype=2, alpha=0.1) + xlab("Coverage of the sample") + ylab("Average correlation")
p<-p+ geom_hline(yintercept=a, linetype="dashed") + ggtitle("MBB for b=10")
plot(p)  

# Fig.9.10b
p1<-ggplot(data=data11, aes(x=interval, y=mea, colour=model)) + geom_point() + geom_line() 
p1<-p1 + geom_ribbon(aes(ymin=data11$lower, ymax=data11$upper), linetype=2, alpha=0.1) + xlab("Coverage of the sample") + ylab("Average correlation")
p1<-p + p1+ geom_hline(yintercept=a, linetype="dashed") + ggtitle("MBB for b=10")
plot(p1)  

# simple sampling
result2<-matrix(0, nrow=30, ncol=20)
colnames(result2)<-paste(rep("cov", times=20), vec)
rownames(result2)<-paste(rep("iter", times=30),1:30)

for(i in 1:20){ # coverage levels - result columns
ile<-380*vec[i] # the total number of observations to be drawn

for(j in 1:30){ # iterations for each coverage level - result rows
lead<-sample(1:380, size= ile, replace=TRUE) # possibly replace = FALSE
boot3<-matrix(0, nrow=ile, ncol=2)
for(k in 1:ile){
boot3[k,1:2]<-as.numeric(unempl[lead[k], 100:101])}
result2[j,i]<-cor(boot3[,1], boot3[,2])}} # correlation

mea2<-as.vector(apply(result2, 2, mean))
sd2<-as.vector(apply(result2, 2, sd))
data2<-as.data.frame(cbind(mea2, sd2))
colnames(data2)<-c("mea", "sd")
data2$lower<-data2$mea-data2$sd
data2$upper<-data2$mea+data2$sd
data2$model<-rep("simple", times=20)
data2$interval<-(20:1)*5/100

data3<-rbind(data, data2) # combining MBB and CR results

# joint MMB and CR chart - thanks to the color option in aes
p<-ggplot(data=data3, aes(x=interval, y=mea, colour=model)) + geom_point() + geom_line() 
p<-p+geom_ribbon(aes(ymin=data3$lower, ymax=data3$upper), linetype=2, alpha=0.1) + xlab ("sample coverage") + ylab ("average correlation") + ggtitle("drawing with replacement")
plot(p) # Fig.9.11a,b

#9.4. Use of spatial sampling and bootstrapping in cross-validation of models 

# Data preparation - selection of variables
unempl<-read.csv("unemp2018.csv", header=TRUE, dec=",", sep=";")
unempl_ml<-unempl[, c(13:101)] # a subset of data dedicated to analysis
crds_ml<-unempl$crds

# imputation of missing data 
unempl_ml[c(248, 286, 344, 359), 1]<-c(631188, 123659, 119171, 102422)

# attaching geographic coordinates to a data set
unempl_ml$x<-crds[,1]
unempl_ml$y<-crds[,2]

# formula of the equation
RHS<-paste(names(unempl_ml)[-90], collapse='+') 
LHS<-names(unempl_ml)[90]

formula_ml<-as.formula(paste0(LHS, '~', RHS))
formula_ml

# Adding a voivodship variable to the data set
unempl_ml$voi<-unempl$region

library(randomForest) # loading the package
set.seed(1234) 
model<-randomForest(formula_ml, data=unempl_ml, ntree=500)# estimation
model # results printout
plot(model) #fit of the model, Fig.9.12

# five maps with locations of sampled points
library(sperrorest)
resamp<-partition_cv(unempl_ml, nfold=5, repetition=1, seed1=1)
plot(resamp, unempl_ml, coords=c("x","y"))

res_rf_cv<-sperrorest(formula_ml, # function formula
              	data = unempl_ml, # database
                  model_fun = randomForest, # function name
                  model_args = list(ntree = 50, # numer of trees 
mtry = 90), # number of variables
                  smp_fun = partition_cv, # sampling function
                  smp_args=list(repetition = 100, # number of repetitions
nfold = 5, # number of folds
seed1 = 1234), # seed for sampling
err_fun = err_default, # goodness-of-fit statistics
                  error_rep = TRUE, # saving errors in each repetition
                  progress = 'all') # printout of progress in the calculation

round(summary(res_rf_cv$error_rep), 3) # Result printout

# A set with an example sample of data
df<-data.frame(prop=c(round(prop.table(table(unempl_ml$voi)), 2), round(prop.table(table(unempl_ml$voi[resamp$`1`$`3`$train])), 2)), labels=c(rep('whole sample (380 poviats)', 16), rep('Sample training set', 16)), voi=c(names(table(unempl_ml$voi)), names(table(unempl_ml$voi))))
head(df)
tail(df)

# Figure – empirical vs. sampled frequency of poviats. 
ggplot(data=df, aes(x=voi, y=prop, fill=labels)) +
  geom_col(position='dodge') +
  theme(axis.text.x=element_text(angle=45, hjust=1, size=7),
        legend.position='bottom',
        legend.title=element_blank()) +
  scale_y_continuous(labels=scales::percent, name='Frequency')

# Generation of sample folders for stratified sampling
resamp<-partition_cv_strat(unempl_ml, nfold=5, repetition=1, seed1=1234, strat='voi')

plot(resamp, unempl_ml, coords=c("x","y")) # Fig.9.13

# Preparation of data for sampling and histogram
df<-data.frame(prop=c(round(prop.table(table(unempl_ml$voi)),2), round(prop.table(table(unempl_ml$voi[resamp$`1`$`3`$train])), 2)), labels=c(rep('whole sample (380 poviats)', 16), rep('Sample training set', 16)), voi=c(names(table(unempl_ml$voi)), names(table(unempl_ml$voi))))

# barplot comparing sampled and empirical frequencies
ggplot(data=df, aes(x=voi, y=prop, fill=labels)) +
  geom_col(position='dodge') +
  theme(axis.text.x=element_text(angle=45, hjust=1, size=10),
        legend.position='bottom', legend.title=element_blank()) +
        scale_y_continuous(labels=scales::percent, name='Frequency')

set.seed(1234)
res_rf_strat<-sperrorest(formula_ml, # formula function
                 data = unempl_ml, # database
                 model_fun = randomForest, # function name
                 model_args = list(ntree = 50, # number of trees 
mtry = 90), # number of variables
                 smp_fun = partition_cv_strat, # sampling function
                 smp_args = list(repetition = 100,
 					nfold = 5, 
seed1 = 1234, 
strat = 'voi'),	
                  error_rep = TRUE, # saving errors in each repetition
                  Progres = 'all') # printout of progress in the calculation

round(summary(res_rf_strat$error_rep), 3) # result printout

# resampling kmeans
resamp<-partition_kmeans(unempl_ml, nfold=5, coords=c('x', 'y'),
                           repetition=1, seed1=1234)
plot(resamp, unempl_ml, coords=c("x","y")) # Fig.9.14

# factor sampling
resamp<-partition_factor_cv(unempl_ml, nfold=5, fac='voi', coords=c('x', 'y'), repetition=1, seed1=1234)

# resampling tiles
resamp<-partition_tiles(unempl_ml, nsplit=c(3,2), coords=c('x', 'y'), repetition=1)
plot(resamp, bezrob_ml, coords = c("x","y"), mfrow =c(3, 2)) # Fig.9.14c

# Random forest with kmeans resampling
resamp <- partition_kmeans(unempl_ml, nfold = 5, coords = c('x', 'y'),
                           repetition = 1, seed1 = 1234)
set.seed(1234)
res_rf_km <- sperrorest(formula_ml, # formula function
                 data = unempl_ml, # database
                 model_fun = randomForest, # function name
                 model_args = list(ntree = 50, # number of trees 
     mtry = 90), # number of variables
                 smp_fun = partition_kmeans, , # sampling function
                 smp_args = list(repetition=100, # number of reps
                                 nfold=5, # number of folds
                                 seed1=1234), # seed for sampling
                        error_rep = TRUE, # saving errors in each rep
                        error_fold = TRUE, # saving errors in each fold
                        progress = 'all') # printout of progress
# Random forest with resampling factor
resamp <- partition_factor_cv(unempl_ml, nfold = 5, fac = 'voi', coords = c('x', 'y'), repetition = 1, seed1 = 1234)

set.seed(1234)
res_rf_fa <- sperrorest(formula_ml, # formula function
                 data = unempl_ml, # database
                 model_fun = randomForest, # function name
                 model_args = list(ntree = 50, # number of trees 
mtry = 90), # number of variables
                        smp_fun = partition_factor_cv, # sampling function
                        smp_args = list(repetition=100, # number of reps
                                        fac='voi', # name of factor var
                                        nfold=5, # number of folds
                                        seed1=1234), # seed for sampling
                        error_rep = TRUE, # saving errors in each rep
                        error_fold = TRUE, # saving errors in each fold
                        progress = 'all') # printout of progress
# Random forest with resampling tiles
resamp <- partition_tiles(unempl_ml, nsplit = c(3, 2), coords =c('x', 'y'),
                          repetition = 1)
set.seed(1234)
res_rf_ti <- sperrorest(formula_ml, # formula function
                        data = unempl_ml, # database                       
                        coords = c("x","y"), #coordinations of obs
                        model_fun = randomForest, # function name
                        model_args = list(ntree = 50, # number of trees 
                                          mtry = 90), # number of variables                                     
                        smp_fun = partition_tiles, # sampling function
                        smp_args = list(repetition = 100, # number of reps
                                        nsplit = c(3, 3),# number of splits
                                        seed1=1234), # seed for sampling
                        error_rep = TRUE, # saving errors in each rep
                        error_fold = TRUE, # saving errors in each fold
                        progress = 'all') # printout of progress


# Preparing data with aggregate results.
df <- data.frame(cv = res_rf_cv$error_rep$test_rmse, 
                 strat = res_rf_strat$error_rep$test_rmse,
                 factor = res_rf_fa$error_rep$test_rmse,
                 kmeans = res_rf_km$error_rep$test_rmse,
                 tile = res_rf_ti$error_rep$test_rmse)

# Fig.9.15
ggplot(data=df) +
  stat_density(aes(x=cv, color='Classic CV'), geom='line')  +
  geom_vline(aes(xintercept=mean(cv), color=' Classic CV'), linetype= 'dashed') +
  stat_density(aes(x=strat, color='stratified CV'), geom='line')  + geom_vline(aes(xintercept=mean(strat), color=' stratified CV'), linetype ='dashed') +
  stat_density(aes(x=factor, color='factor CV'), geom='line')  +
  geom_vline(aes(xintercept=mean(factor), color=' factor CV'), linetype ='dashed') +
  stat_density(aes(x=kmeans, color='kmeans CV'), geom='line')  +
  geom_vline(aes(xintercept=mean(kmeans), color='kmeans CV'), linetype = 'dashed') +
  stat_density(aes(x=tile, color='tiles CV'), geom='line')  +
  geom_vline(aes(xintercept=mean(tile), color='tiles CV'), linetype = 'dashed') +
  theme(legend.position='bottom', legend.title=element_blank())
